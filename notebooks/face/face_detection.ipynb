{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee05e03",
   "metadata": {},
   "source": [
    "# Prepare environment\n",
    "\n",
    "## Configure jupyter\n",
    "\n",
    "* Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install cmake\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edcc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# run all code cells of the specified notebook\n",
    "%run ../face/libs/image_utils.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b024405",
   "metadata": {},
   "source": [
    "# Use DeepFace library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "backend_names = [\"opencv\", \"ssd\", \"dlib\", \"mtcnn\", \"retinaface\", \"mediapipe\"]\n",
    "model_names = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"ArcFace\"]\n",
    "# model_names = [\"VGG-Face\", \"Facenet\", \"Facenet512\", \"OpenFace\", \"DeepFace\", \"ArcFace\", \"DeepID\", \"Dlib\", \"SFace\"]\n",
    "\n",
    "target_size=(224, 224)\n",
    "\n",
    "face_path = '/data/faces/'\n",
    "person_path = face_path + 'elon_musk/'\n",
    "face1 = person_path + 'image1.jpeg'\n",
    "face2 = person_path + 'image2.jpeg'\n",
    "face_double = person_path + 'image_double.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946a80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ GRAYSCALE\n",
    "img = img_read_cv(face1, cv2.IMREAD_GRAYSCALE)\n",
    "img = img_convert_color(img)\n",
    "img_show_using_color(img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dd297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, backend_name in enumerate(backend_names):\n",
    "    try:\n",
    "        face = DeepFace.detectFace(face_double, target_size=target_size, detector_backend=backend_name)\n",
    "        img_show_axis(img=face, axis=axs[index], title=backend_name)\n",
    "    except:\n",
    "        pass\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    result = DeepFace.verify(\n",
    "        img1_path = face1,\n",
    "        img2_path = face2,\n",
    "        model_name=model_name\n",
    "    )\n",
    "    print(model_name, '=>', result)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    fig.suptitle(f'Verified {result[\"verified\"]} - Distance {result[\"distance\"]:0.4}')\n",
    "\n",
    "    img_show_axis(img=face1, axis=axs[0], func=plt.imread)\n",
    "    img_show_axis(img=face2, axis=axs[1], func=plt.imread)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf035fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = DeepFace.find(img_path=face1, db_path=face_path)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "imgs = glob(person_path + \"*\")\n",
    "\n",
    "for img_path in imgs:\n",
    "    analysis = DeepFace.analyze(\n",
    "        img_path=img_path, \n",
    "        detector_backend=backend_names[4]\n",
    "    )\n",
    "    emo_df = pd.DataFrame(analysis[0][\"emotion\"], index=[0]).T.rename(\n",
    "        columns={0: \"prediction\"}\n",
    "    )\n",
    "    img_show_axis_values(img_path, emo_df.sort_values(\"prediction\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d10cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
