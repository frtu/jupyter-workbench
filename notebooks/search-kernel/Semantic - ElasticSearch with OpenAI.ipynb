{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ede3d13b-18d5-4c62-9aa2-94523f4e6ab2",
   "metadata": {},
   "source": [
    "# Prepare environment\n",
    "\n",
    "* https://cookbook.openai.com/examples/vector_databases/elasticsearch/elasticsearch-semantic-search\n",
    "\n",
    "## Init base libs\n",
    "\n",
    "* Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c03cfae-e3f7-4450-9677-ecfa5074c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install \\\n",
    "    python-dotenv \\\n",
    "    pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c22f5a-bdb2-4b9f-a3f8-fa7ae6f62c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb00ad-0282-4512-bd41-08502b2f2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def read_yaml_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads YAML file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "    \n",
    "# config = read_yaml_file(\"./config.yml\")\n",
    "# config[\"cloud_id\"], api_key=config[\"api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980d59d-6174-49c3-a753-c2d2c6543a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads and loads a JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40166136-ff0e-49b2-a1d6-cdc3c4592199",
   "metadata": {},
   "source": [
    "## Init ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a016a10-b423-44f2-acbf-dab7417c57e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install \\\n",
    "    elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191d661-a3bd-42b2-a922-010b379a2c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "def get_client_es(hosts:str=\"http://elasticsearch:9200\", max_retries:int=5, request_timeout:int=600):\n",
    "    \"\"\"\n",
    "    Initializes Elasticsearch client using cloud_id and api_key from config.yml\n",
    "    \"\"\"\n",
    "    es = Elasticsearch(hosts=hosts, request_timeout=request_timeout)\n",
    "    return es.options(max_retries=max_retries)\n",
    "\n",
    "es = get_client_es()\n",
    "es.info() # should return cluster info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e21cf7-ff3a-4904-be53-b28629c2b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.elastic.co/search-labs/tutorials/search-tutorial/full-text-search/create-index\n",
    "def create_index(index_name: str, mappings):\n",
    "    es = get_client_es()\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        response = es.indices.create(index=index_name, body=mappings)\n",
    "        if response.meta.status != 200:\n",
    "            raise RuntimeError(\"failed to create index\")\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' already exists.\")\n",
    "        response = es.indices.get(index=index_name)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d9936b-77cf-4b7b-b8aa-82c5059a5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_index(index_name: str) -> int:\n",
    "    es = get_client_es()\n",
    "    count = int(es.cat.count(index=index_name, format=\"json\")[0][\"count\"])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f9c1e-da65-407f-9dd6-0bf676ec6cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_index(index_name: str, body):\n",
    "    es = get_client_es()\n",
    "    response = es.search(index=index_name, body=body)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91585eec-02f1-4d73-a755-c2fcb04e29eb",
   "metadata": {},
   "source": [
    "## Init openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca6dc9-ab17-42ab-9749-5b6c16160b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# https://platform.openai.com/docs/libraries\n",
    "%pip install \\\n",
    "    openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b5dcc-74f4-46ce-b442-3e225080af15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # for calling the OpenAI API\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Load your API key from an environment variable or secret management service\n",
    "# openai.api_key = getpass(\"Enter OpenAI API key\") # os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key = os.getenv(\"OPENAI_API_KEY\") # getpass(\"Enter OpenAI API key\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46227ffa-7f56-45c1-9f7d-9a7b53664837",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ebb77-fe94-4811-b5c7-31bddf76195c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "normalize_text(\"\"\"\n",
    "Apple is a corporate structure\n",
    " that\n",
    " \n",
    " is famous\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16067727-4a7f-4109-9b0f-fd066aefcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using openai.Embedding syntax\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    filtered_text = normalize_text(text)\n",
    "    return client.embeddings.create(input = [filtered_text], model=model).data[0].embedding\n",
    "\n",
    "embeddings = get_embedding(\"Is the Atlantic the biggest ocean in the world?\", model='text-embedding-3-small')\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86350c71-8665-4f54-ae75-9b5d761c90b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Loading dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9dfd02-0037-4986-bda4-98b203c2d3b2",
   "metadata": {},
   "source": [
    "## Loading dataset from OpenAI Cookbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3b033-7c35-435c-9fc0-ce3a6eae8bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install \\\n",
    "    wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd15074d-6bcb-4e70-9532-6aeaa5d3193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "\n",
    "folder = \"/data/wikipedia/\"\n",
    "\n",
    "embeddings_url = 'https://cdn.openai.com/API/examples/data/vector_database_wikipedia_articles_embedded.zip'\n",
    "wget.download(embeddings_url)\n",
    "\n",
    "with zipfile.ZipFile(\"vector_database_wikipedia_articles_embedded.zip\",\n",
    "\"r\") as zip_ref:\n",
    "    zip_ref.extractall(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fe25d-c905-4405-89cc-0dc5d796976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "folder = \"/data/wikipedia/\"\n",
    "\n",
    "dataset_file = folder + \"vector_database_wikipedia_articles_embedded.csv\"\n",
    "df = pd.read_csv(dataset_file)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a878b-edf5-4142-a332-d0e0150bfc25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.elastic.co/guide/en/elasticsearch/reference/current/knn-search-api.html\n",
    "\n",
    "index_name = \"wikipedia_vector_index\"\n",
    "mapping = {\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"title_vector\": {\n",
    "          \"type\": \"dense_vector\",\n",
    "          \"dims\": 1536,\n",
    "          \"index\": \"true\",\n",
    "          \"similarity\": \"cosine\"\n",
    "      },\n",
    "      \"content_vector\": {\n",
    "          \"type\": \"dense_vector\",\n",
    "          \"dims\": 1536,\n",
    "          \"index\": \"true\",\n",
    "          \"similarity\": \"cosine\"\n",
    "      },\n",
    "      \"text\": {\"type\": \"text\"},\n",
    "      \"title\": {\"type\": \"text\"},\n",
    "      \"url\": { \"type\": \"keyword\"},\n",
    "      \"vector_id\": {\"type\": \"long\"}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "create_index(index_name, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094994d2-1dac-4cad-b207-29ea7c11e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def dataframe_to_bulk_actions(df):\n",
    "    for index, row in df.iterrows():\n",
    "        yield {\n",
    "            \"_index\": index_name,\n",
    "            \"_id\": row['id'],\n",
    "            \"_source\": {\n",
    "                'url' : row[\"url\"],\n",
    "                'title' : row[\"title\"],\n",
    "                'text' : row[\"text\"],\n",
    "                'title_vector' : json.loads(row[\"title_vector\"]),\n",
    "                'content_vector' : json.loads(row[\"content_vector\"]),\n",
    "                'vector_id' : row[\"vector_id\"]\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb23d57-40a2-441e-9149-bee408b24a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = len(df)\n",
    "batch_size = 100\n",
    "\n",
    "for batch_start in range(start, end, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, end)\n",
    "    batch_dataframe = df.iloc[batch_start:batch_end]\n",
    "    actions = dataframe_to_bulk_actions(batch_dataframe)\n",
    "    \n",
    "    helpers.bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc2b3d1-bb21-4f1f-9db7-31251da63c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(es.search(index=index_name, body={\n",
    "    \"_source\": {\n",
    "        \"excludes\": [\"title_vector\", \"content_vector\"]\n",
    "    },\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\": {\n",
    "                \"query\": \"Hummingbird\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd1ac7-2c3e-4cfb-bdee-e7249a0fabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pretty print Elasticsearch results\n",
    "\n",
    "def pretty_response(response):\n",
    "    for hit in response['hits']['hits']:\n",
    "        id = hit['_id']\n",
    "        score = hit['_score']\n",
    "        title = hit['_source']['title']\n",
    "        text = hit['_source']['text']\n",
    "        pretty_output = (f\"\\nID: {id}\\nTitle: {title}\\nSummary: {text}\\nScore: {score}\")\n",
    "        print(pretty_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b1769-ea98-4f9e-8039-5a15d6cedaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embedding = get_embedding('Is the Atlantic the biggest ocean in the world?')\n",
    "\n",
    "response = es.search(\n",
    "  index = \"wikipedia_vector_index\",\n",
    "  knn={\n",
    "      \"field\": \"content_vector\",\n",
    "      \"query_vector\": question_embedding,\n",
    "      \"k\": 10,\n",
    "      \"num_candidates\": 100\n",
    "    }\n",
    ")\n",
    "pretty_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e010892-e241-4619-9b2f-d949e5d01bd6",
   "metadata": {},
   "source": [
    "### Unstructured IO\n",
    "\n",
    "https://github.com/Unstructured-IO/unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cdeb9-bbe9-443b-99be-8df273f83926",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install \\\n",
    "    unstructured-ingest[chroma, confluence, elasticsearch, gcs, github, gitlab, google-drive, jira, kafka, notion, onedrive, openai, postgres, qdrant, reddit, slack, wikipedia] \\\n",
    "    unstructured[pdf,embed-huggingface]<0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53282d0a-3ef9-4f5e-82ab-333c850bcede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from unstructured.embed.huggingface import (\n",
    "    HuggingFaceEmbeddingConfig,\n",
    "    HuggingFaceEmbeddingEncoder,\n",
    ")\n",
    "\n",
    "def embeddings_for_text(text: str) -> List[float]:\n",
    "    embedding_encoder = HuggingFaceEmbeddingEncoder(config=HuggingFaceEmbeddingConfig())\n",
    "    return embedding_encoder.embed_query(text)\n",
    "\n",
    "def get_embeddings_len(index_name: str):\n",
    "    es = get_client_es()\n",
    "    res = es.search(index=index_name, size=1, query={\"match_all\": {}})\n",
    "    return len(res[\"hits\"][\"hits\"][0][\"_source\"][\"embeddings\"])\n",
    "\n",
    "def query(index_name: str, search_text: str):\n",
    "    # Query the index using the appropriate embedding vector for given query text\n",
    "    search_vector = embeddings_for_text(search_text)\n",
    "    # Constructing the search query\n",
    "    return search_index(index_name=index_name, body={\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\"match_all\": {}},\n",
    "                \"script\": {\n",
    "                    \"source\": \"cosineSimilarity(params.query_vector, 'embeddings') + 1.0\",\n",
    "                    \"params\": {\"query_vector\": search_vector},\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "embeddings_for_text(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b8a4e-f53d-40e8-ac80-a05653f47869",
   "metadata": {},
   "source": [
    "# Create tables\n",
    "\n",
    "### Unstructured\n",
    "\n",
    "Ex : https://github.com/Unstructured-IO/unstructured/blob/main/scripts/elasticsearch-test-helpers/destination_connector/test-ingest-elasticsearch-output.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d7dbce-5a7e-4f15-890b-04cf054fee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"unstructured-ingest-test\"\n",
    "mappings = read_json_file(\"/data/search/\" + index_name + \"/_index_mappings.json\")\n",
    "\n",
    "print(\"== Connecting to the Elasticsearch cluster ==\")\n",
    "es = get_client_es()\n",
    "print(f\"{es.info()}\")\n",
    "\n",
    "print(\"== Creating an Elasticsearch index for testing ingest elasticsearch destination connector ==\")\n",
    "response = create_index(index_name=index_name, mappings=mappings)\n",
    "\n",
    "es.indices.refresh(index=index_name)\n",
    "response = es.cat.count(index=index_name, format=\"json\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4bb95-8a38-4dcc-99d2-270b7943f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_index(\"products-catalog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cd73f8-e757-4d74-a837-b05ce7590e7e",
   "metadata": {},
   "source": [
    "### ES Product catalog\n",
    "\n",
    " Example : https://github.com/elastic/elasticsearch-labs/tree/main/supporting-blog-content/hybrid-search-for-an-e-commerce-product-catalogue/product-store-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12ad1d-530f-4da3-bf3a-f4b4d62138c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"products-catalog\"\n",
    "mapping = {\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_replicas\": 0,\n",
    "            \"number_of_shards\": 1,\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"brand\": {\n",
    "                \"type\": \"text\",\n",
    "                \"fields\": {\"keyword\": {\"type\": \"keyword\"}},\n",
    "            },\n",
    "            \"name\": {\"type\": \"text\"},\n",
    "            \"price\": {\"type\": \"float\"},\n",
    "            \"price_sign\": {\"type\": \"keyword\"},\n",
    "            \"currency\": {\"type\": \"keyword\"},\n",
    "            \"image_link\": {\"type\": \"keyword\"},\n",
    "            \"description\": {\"type\": \"text\"},\n",
    "            \"description_embeddings\": {\"type\": \"dense_vector\", \"dims\": 384},\n",
    "            \"rating\": {\"type\": \"keyword\"},\n",
    "            \"category\": {\"type\": \"keyword\"},\n",
    "            \"product_type\": {\"type\": \"keyword\"},\n",
    "            \"tag_list\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "create_index(index_name, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ce5ec7-d5a7-426b-a9e6-8e2ef50961fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(term=None, categories=None, product_types=None, brands=None):\n",
    "    must_query = (\n",
    "        [{\"match_all\": {}}]\n",
    "        if not term\n",
    "        else [\n",
    "            {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": term,\n",
    "                    \"fields\": [\"name\", \"category\", \"description\"],\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    filters = []\n",
    "    if categories:\n",
    "        filters.append({\"terms\": {\"category\": categories}})\n",
    "    if product_types:\n",
    "        filters.append({\"terms\": {\"product_type\": product_types}})\n",
    "    if brands:\n",
    "        filters.append({\"terms\": {\"brand.keyword\": brands}})\n",
    "    return {\n",
    "        \"_source\": [\n",
    "            \"id\",\n",
    "            \"brand\",\n",
    "            \"name\",\n",
    "            \"price\",\n",
    "            \"currency\",\n",
    "            \"image_link\",\n",
    "            \"category\",\n",
    "            \"tag_list\",\n",
    "        ],\n",
    "        \"query\": {\"bool\": {\"must\": must_query, \"filter\": filters}},\n",
    "    }\n",
    "\n",
    "\n",
    "def build_hybrid_query(term=None, categories=None, product_types=None, brands=None, hybrid=False):\n",
    "    # Standard query\n",
    "    organic_query = build_query(term, categories, product_types, brands)\n",
    "\n",
    "    if hybrid is True and term:\n",
    "        vector = get_text_vector([term])[0]\n",
    "        # Hybrid query with RRF (Reciprocal Rank Fusion)\n",
    "        query = {\n",
    "            \"retriever\": {\n",
    "                \"rrf\": {\n",
    "                    \"retrievers\": [\n",
    "                        {\"standard\": {\"query\": organic_query[\"query\"]}},\n",
    "                        {\n",
    "                            \"knn\": {\n",
    "                                \"field\": \"description_embeddings\",\n",
    "                                \"query_vector\": vector,\n",
    "                                \"k\": 5,\n",
    "                                \"num_candidates\": 20,\n",
    "                                \"filter\": {\"bool\": {\"filter\": []}},\n",
    "                            }\n",
    "                        },\n",
    "                    ],\n",
    "                    \"rank_window_size\": 20,\n",
    "                    \"rank_constant\": 5,\n",
    "                }\n",
    "            },\n",
    "            \"_source\": organic_query[\"_source\"],\n",
    "        }\n",
    "        if categories:\n",
    "            query[\"retriever\"][\"rrf\"][\"retrievers\"][1][\"knn\"][\"filter\"][\"bool\"][\n",
    "                \"filter\"\n",
    "            ].append({\"terms\": {\"category\": categories}})\n",
    "        if product_types:\n",
    "            query[\"retriever\"][\"rrf\"][\"retrievers\"][1][\"knn\"][\"filter\"][\"bool\"][\n",
    "                \"filter\"\n",
    "            ].append({\"terms\": {\"product_type\": product_types}})\n",
    "        if brands:\n",
    "            query[\"retriever\"][\"rrf\"][\"retrievers\"][1][\"knn\"][\"filter\"][\"bool\"][\n",
    "                \"filter\"\n",
    "            ].append({\"terms\": {\"brand.keyword\": brands}})\n",
    "    else:\n",
    "        query = organic_query\n",
    "\n",
    "    return query\n",
    "\n",
    "def search_products(\n",
    "    term,\n",
    "    categories=None,\n",
    "    product_types=None,\n",
    "    brands=None,\n",
    "    promote_products=[],\n",
    "    hybrid=False,\n",
    "):\n",
    "    query = build_hybrid_query(term, categories, product_types, brands, hybrid)\n",
    "\n",
    "    if promote_products and not hybrid:\n",
    "        query = {\n",
    "            \"query\": {\"pinned\": {\"ids\": promote_products, \"organic\": query[\"query\"]}},\n",
    "            \"_source\": query[\"_source\"],\n",
    "        }\n",
    "\n",
    "    print(query)\n",
    "    response = get_client_es().search(index=\"products-catalog\", body=query, size=20)\n",
    "\n",
    "    results = []\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        print(f\"Product Name: {hit['_source']['name']}, Score: {hit['_score']}\")\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"id\": hit[\"_source\"][\"id\"],\n",
    "                \"brand\": hit[\"_source\"][\"brand\"],\n",
    "                \"name\": hit[\"_source\"][\"name\"],\n",
    "                \"price\": hit[\"_source\"][\"price\"],\n",
    "                \"currency\": (\n",
    "                    hit[\"_source\"][\"currency\"] if hit[\"_source\"][\"currency\"] else \"USD\"\n",
    "                ),\n",
    "                \"image_link\": hit[\"_source\"][\"image_link\"],\n",
    "                \"category\": hit[\"_source\"][\"category\"],\n",
    "                \"tags\": hit[\"_source\"].get(\"tag_list\", []),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_facets_data(term, categories=None, product_types=None, brands=None):\n",
    "    query = build_query(term, categories, product_types, brands)\n",
    "    query[\"aggs\"] = {\n",
    "        \"product_types\": {\"terms\": {\"field\": \"product_type\"}},\n",
    "        \"categories\": {\"terms\": {\"field\": \"category\"}},\n",
    "        \"brands\": {\"terms\": {\"field\": \"brand.keyword\"}},\n",
    "    }\n",
    "    response = get_client_es().search(index=\"products-catalog\", body=query, size=0)\n",
    "\n",
    "    return {\n",
    "        \"product_types\": [\n",
    "            {\"product_type\": bucket[\"key\"], \"count\": bucket[\"doc_count\"]}\n",
    "            for bucket in response[\"aggregations\"][\"product_types\"][\"buckets\"]\n",
    "        ],\n",
    "        \"categories\": [\n",
    "            {\"category\": bucket[\"key\"], \"count\": bucket[\"doc_count\"]}\n",
    "            for bucket in response[\"aggregations\"][\"categories\"][\"buckets\"]\n",
    "        ],\n",
    "        \"brands\": [\n",
    "            {\"brand\": bucket[\"key\"], \"count\": bucket[\"doc_count\"]}\n",
    "            for bucket in response[\"aggregations\"][\"brands\"][\"buckets\"]\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39822073-0777-4545-bdc7-e8cfdad19130",
   "metadata": {},
   "source": [
    "## Chunk data for batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab5bdd3-6f21-4c72-8493-1df8591174af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, batch_size):\n",
    "    \"\"\"\n",
    "    Yields chunks of data in batch sizes for bulk indexing in Elasticsearch.\n",
    "    \"\"\"\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i : i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876bc922-c5e5-49f7-8f82-3cd14bb5f650",
   "metadata": {},
   "source": [
    "## Generate bulk actions for Elasticsearch indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae032cc6-3728-4c12-8520-0fce8ea3a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bulk_actions(index_name, data_batch):\n",
    "    \"\"\"\n",
    "    Generates bulk actions for Elasticsearch from data batches.\n",
    "    Adds 'description_embeddings' by encoding the 'description' field.\n",
    "    \"\"\"\n",
    "    for item in data_batch:\n",
    "        document_id = item[\"id\"]\n",
    "        item[\"description_embeddings\"] = get_text_vector(item[\"description\"])\n",
    "        yield {\"_index\": index_name, \"_id\": document_id, \"_source\": item}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11b0e6-bace-4761-9fbe-003b3ac4c013",
   "metadata": {},
   "source": [
    "## Indexing data in batches to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffd2fbf-e3e8-405d-8c02-e47895b0e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_data_in_batches(file_path, index_name, batch_size=100):\n",
    "    \"\"\"\n",
    "    Indexes data from the JSON file in batches using Elasticsearch helpers.bulk.\n",
    "    \"\"\"\n",
    "    data = read_json_file(file_path)\n",
    "\n",
    "    for batch in chunk_data(data, batch_size):\n",
    "        actions = generate_bulk_actions(index_name, batch)\n",
    "        success, failed = helpers.bulk(get_client_es(), actions)\n",
    "        print(f\"Batch indexed: {success} successful, {failed} failed\")\n",
    "\n",
    "\n",
    "# main execution block\n",
    "# if __name__ == '__main__':\n",
    "#     index_data_in_batches(\"../files/dataset/products.json\", \"products-catalog\", batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1961f12-0535-4647-a4c1-344961baa092",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_in_batches(\n",
    "    \"/data/search/product-store-search/products.json\", \"products-catalog\", batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a3c6b-90b1-4e7f-8f44-4a73bf54da8c",
   "metadata": {},
   "source": [
    "# Semantic Search\n",
    "\n",
    "## Sentence transformer\n",
    "\n",
    "https://sbert.net/docs/quickstart.html\n",
    "\n",
    "* max_seq_length : max # of tokens encoded into a single vector embedding. Beyond is truncated\n",
    "* word_embedding_dimension : # of dimensionality of vector\n",
    "* Normalize : final step is normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59bcf63-22bd-4d3f-8e8e-50ca61fd65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "embeddings = get_text_vector(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# => Calculate the embedding similarities\n",
    "# similarities = model.similarity(embeddings, embeddings)\n",
    "# print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fea98d-4a35-49f1-94b9-35b745bfc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'which city is the most populated in the world'\n",
    "\n",
    "embeddings = model.encode(query)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f207e-bd92-4e33-8e51-ea1820507886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "_id = '0'\n",
    "metadata = {'text': query}\n",
    "vectors = [{_id, embeddings, metadata}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf2bb7-e874-4fba-b6ee-214fc504e904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
